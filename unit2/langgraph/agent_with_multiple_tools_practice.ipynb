{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MlefPBYvbJ3H",
        "UBT-T8S7d83K",
        "kUshIDNbd5gP",
        "qBTMZfK--nTV",
        "FXKcZPYP-pfJ",
        "eHoB0slCa5d2"
      ],
      "authorship_tag": "ABX9TyNSopBa5y46MF3VDtcocek/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BanSangSu/Huggingface-AI-Agents-course/blob/main/unit2/langgraph/agent_with_multiple_tools_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import & API keys"
      ],
      "metadata": {
        "id": "MlefPBYvbJ3H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k3ABie_OD6z"
      },
      "outputs": [],
      "source": [
        "%pip install -U rank_bm25 datasets langchain langchain_community langchain_openai langgraph langchain_core duckduckgo-search pyowm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# huggingface api\n",
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "uNjgTwN4cW8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# weather api\n",
        "os.environ[\"OPENWEATHERMAP_API_KEY\"] = getpass()\n",
        "\n",
        "# llm api\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"OPENAI_API_BASE\"] = getpass(\"OpenAI OPENAI BASE URL:\")"
      ],
      "metadata": {
        "id": "RQadBGk9cZGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools\n",
        "(You can use these tools independently by creating standalone Python (.py) modules)"
      ],
      "metadata": {
        "id": "UBT-T8S7d83K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retriever Tool"
      ],
      "metadata": {
        "id": "TLKr0ICmc3zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "guest_dataset = datasets.load_dataset(\"agents-course/unit3-invitees\", split=\"train\")\n",
        "\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"\\n\".join([\n",
        "            f\"Name: {guest['name']}\",\n",
        "            f\"Relation: {guest['relation']}\",\n",
        "            f\"Description: {guest['description']}\",\n",
        "            f\"Email: {guest['email']}\"\n",
        "        ]),\n",
        "        metadata={\"name\": guest[\"name\"]}\n",
        "    )\n",
        "    for guest in guest_dataset\n",
        "]\n",
        "\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.tools import Tool\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(docs)\n",
        "\n",
        "def extract_text(query: str) -> str:\n",
        "    \"\"\"Retrieves detailed information about gala guests based on their name or relation.\"\"\"\n",
        "    results = bm25_retriever.invoke(query)\n",
        "    if results:\n",
        "        return \"\\n\\n\".join([doc.page_content for doc in results[:3]])\n",
        "    else:\n",
        "        return \"No matching guest information found.\"\n",
        "\n",
        "guest_info_tool = Tool(\n",
        "    name=\"guest_info_retriever\",\n",
        "    description=\"Retrieves detailed information about gala guests based on their name or relation.\",\n",
        "    func=extract_text\n",
        ")"
      ],
      "metadata": {
        "id": "Qb80nZ4MdJ7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Web search, Weather information & Hub Stats tools"
      ],
      "metadata": {
        "id": "iU7fnqf0c7Uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search_tool = DuckDuckGoSearchRun()"
      ],
      "metadata": {
        "id": "isEAde3Z1MkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "from langchain_community.utilities import OpenWeatherMapAPIWrapper\n",
        "\n",
        "def get_weather_info(location: str) -> str:\n",
        "    \"\"\"Fetches dummy weather information for a given location.\n",
        "    You have to type city,Country Code . ex) Seoul,KR \"\"\"\n",
        "    weather = OpenWeatherMapAPIWrapper()\n",
        "\n",
        "    weather_data = weather.run(location)\n",
        "\n",
        "    return weather_data\n",
        "\n",
        "\n",
        "weather_info_tool = Tool(\n",
        "    name=\"get_weather_info\",\n",
        "    func=get_weather_info,\n",
        "    description=\"Fetches dummy weather information for a given location. You have to type city,Country Code . ex) Seoul,KR \"\n",
        ")"
      ],
      "metadata": {
        "id": "aYj-btKld76e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "from huggingface_hub import list_models\n",
        "\n",
        "def get_hub_stats(author: str) -> str:\n",
        "    \"\"\"Fetches the most downloaded model from a specific author on the Hugging Face Hub.\"\"\"\n",
        "    try:\n",
        "        models = list(list_models(author=author, sort=\"downloads\", direction=-1, limit=1))\n",
        "\n",
        "        if models:\n",
        "            model = models[0]\n",
        "            return f\"The most downloaded model by {author} is {model.id} with {model.downloads:,} downloads.\"\n",
        "        else:\n",
        "            return f\"No models found for author {author}.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching models for {author}: {str(e)}\"\n",
        "\n",
        "\n",
        "hub_stats_tool = Tool(\n",
        "    name=\"get_hub_stats\",\n",
        "    func=get_hub_stats,\n",
        "    description=\"Fetches the most downloaded model from a specific author on the Hugging Face Hub.\"\n",
        ")"
      ],
      "metadata": {
        "id": "vIO2mm0T1Qqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Complete Agent"
      ],
      "metadata": {
        "id": "kUshIDNbd5gP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import AnyMessage, HumanMessage, AIMessage\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.graph import START, StateGraph\n",
        "from langgraph.prebuilt import tools_condition\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "## When you import tools from standalone python files.\n",
        "# from tools import DuckDuckGoSearchRun, weather_info_tool, hub_stats_tool\n",
        "# from retriever import guest_info_tool"
      ],
      "metadata": {
        "id": "g2AIOlw8f7CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set the LLM model"
      ],
      "metadata": {
        "id": "qBTMZfK--nTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = getpass(\"Model:\")"
      ],
      "metadata": {
        "id": "qyTO4KA1cjyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=model,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "tools = [guest_info_tool, search_tool, weather_info_tool, hub_stats_tool]\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "1fXIND9S-PkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build LangGraph"
      ],
      "metadata": {
        "id": "FXKcZPYP-pfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Any\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]\n",
        "\n",
        "def assistant(state: AgentState) -> Dict[str, List[Any]]:\n",
        "    return {\n",
        "        \"messages\": [llm_with_tools.invoke(state[\"messages\"])],\n",
        "    }\n",
        "\n",
        "builder = StateGraph(AgentState)\n",
        "\n",
        "builder.add_node(\"assistant\", assistant)\n",
        "builder.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "builder.add_edge(START, \"assistant\")\n",
        "builder.add_conditional_edges(\n",
        "    \"assistant\",\n",
        "    tools_condition,\n",
        ")\n",
        "builder.add_edge(\"tools\", \"assistant\")\n",
        "alfred = builder.compile()"
      ],
      "metadata": {
        "id": "h6ymYCN0d6Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using tool examples"
      ],
      "metadata": {
        "id": "eHoB0slCa5d2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = alfred.invoke({\"messages\": \"Tell me about 'Lady Ada Lovelace'\"})\n",
        "\n",
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response['messages'][-1].content)"
      ],
      "metadata": {
        "id": "w_j-9Mgya9Mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = alfred.invoke({\"messages\": \"What's the weather like in Paris tonight? Will it be suitable for our fireworks display?\"})\n",
        "\n",
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response['messages'][-1].content)"
      ],
      "metadata": {
        "id": "BcQDouPGAC0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = alfred.invoke({\"messages\": \"One of our guests is from Qwen. What can you tell me about their most popular model?\"})\n",
        "\n",
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response['messages'][-1].content)"
      ],
      "metadata": {
        "id": "V-VreNyJByfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = alfred.invoke({\"messages\":\"I need to speak with 'Dr. Nikola Tesla' about recent advancements in wireless energy. Can you help me prepare for this conversation?\"})\n",
        "\n",
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response['messages'][-1].content)"
      ],
      "metadata": {
        "id": "-_bglYe0B0F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversation Memory"
      ],
      "metadata": {
        "id": "68nGoq5-CWBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = alfred.invoke({\"messages\": [HumanMessage(content=\"Tell me about 'Lady Ada Lovelace'. What's her background and how is she related to me?\")]})\n",
        "\n",
        "\n",
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response['messages'][-1].content)\n",
        "print()\n",
        "\n",
        "response = alfred.invoke({\"messages\": response[\"messages\"] + [HumanMessage(content=\"What projects is she currently working on?\")]})\n",
        "\n",
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response['messages'][-1].content)"
      ],
      "metadata": {
        "id": "zv4i9fcECDOy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}