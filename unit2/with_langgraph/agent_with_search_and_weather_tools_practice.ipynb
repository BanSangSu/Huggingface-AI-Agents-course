{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzLNx7efQhpRRewRuhYYF+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BanSangSu/Huggingface-AI-Agents-course/blob/main/unit2/with_langgraph/agent_with_search_and_weather_tools_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dDANDZrg8y9"
      },
      "outputs": [],
      "source": [
        "%pip install -U langchain langchain_community langchain_openai langgraph langchain_core duckduckgo-search pyowm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Access to the Web (search)"
      ],
      "metadata": {
        "id": "TCADyYIil1xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search_tool = DuckDuckGoSearchRun()\n",
        "results = search_tool(\"Who's the current President of Korea?\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "RCCwNogdqHiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Custom Tool for Weather Information to Schedule the Fireworks"
      ],
      "metadata": {
        "id": "6TXxNTJVl6Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENWEATHERMAP_API_KEY\"] = getpass()"
      ],
      "metadata": {
        "id": "6Nv44xNxuyh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "from langchain_community.utilities import OpenWeatherMapAPIWrapper\n",
        "\n",
        "def get_weather_info(location: str) -> str:\n",
        "    \"\"\"Fetches dummy weather information for a given location.\n",
        "    You have to type city,Country Code . ex) Seoul,KR \"\"\"\n",
        "    weather = OpenWeatherMapAPIWrapper()\n",
        "\n",
        "    weather_data = weather.run(location)\n",
        "\n",
        "    return weather_data\n",
        "\n",
        "\n",
        "weather_info_tool = Tool(\n",
        "    name=\"get_weather_info\",\n",
        "    func=get_weather_info,\n",
        "    description=\"Fetches dummy weather information for a given location. You have to type city,Country Code . ex) Seoul,KR \"\n",
        ")"
      ],
      "metadata": {
        "id": "Sr81bceCl6dN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Hub Stats Tool for Influential AI Builders"
      ],
      "metadata": {
        "id": "GUoqLQiPl85Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login()"
      ],
      "metadata": {
        "id": "UnBS0v32w2LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "from huggingface_hub import list_models\n",
        "\n",
        "def get_hub_stats(author: str) -> str:\n",
        "    \"\"\"Fetches the most downloaded model from a specific author on the Hugging Face Hub.\"\"\"\n",
        "    try:\n",
        "        models = list(list_models(author=author, sort=\"downloads\", direction=-1, limit=1))\n",
        "\n",
        "        if models:\n",
        "            model = models[0]\n",
        "            return f\"The most downloaded model by {author} is {model.id} with {model.downloads:,} downloads.\"\n",
        "        else:\n",
        "            return f\"No models found for author {author}.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching models for {author}: {str(e)}\"\n",
        "\n",
        "\n",
        "hub_stats_tool = Tool(\n",
        "    name=\"get_hub_stats\",\n",
        "    func=get_hub_stats,\n",
        "    description=\"Fetches the most downloaded model from a specific author on the Hugging Face Hub.\"\n",
        ")\n",
        "\n",
        "print(hub_stats_tool(\"facebook\"))"
      ],
      "metadata": {
        "id": "0wuwehfXl9Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Integrating Tools with Alfred (LLM)"
      ],
      "metadata": {
        "id": "Y6dZhnoul9x-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"OPENAI_API_BASE\"] = getpass(\"OpenAI OPENAI BASE URL:\")"
      ],
      "metadata": {
        "id": "9CEYt7kmxMP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "model = getpass(\"Model:\")"
      ],
      "metadata": {
        "id": "RfUzWnwSx2tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=model,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "tools = [search_tool, weather_info_tool, hub_stats_tool]\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "vgCV0AtOmCtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate the AgentState and Agent graph"
      ],
      "metadata": {
        "id": "HJUquNj7y61m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import AnyMessage, HumanMessage, AIMessage\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.graph import START, StateGraph\n",
        "from langgraph.prebuilt import tools_condition\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]\n",
        "\n",
        "\n",
        "def assistant(state: AgentState):\n",
        "    return {\n",
        "        \"messages\": llm_with_tools.invoke(state[\"messages\"]),\n",
        "    }\n",
        "\n",
        "builder = StateGraph(AgentState)\n",
        "\n",
        "builder.add_node(\"assistant\", assistant)\n",
        "builder.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "builder.add_edge(START, \"assistant\")\n",
        "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
        "builder.add_edge(\"tools\", \"assistant\")\n",
        "\n",
        "alfred = builder.compile()"
      ],
      "metadata": {
        "id": "tHQCQUYsy3mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"Who is Facebook and what's their most popular model?\")]\n",
        "response = alfred.invoke({\"messages\": messages})"
      ],
      "metadata": {
        "id": "W_BELZXb4M61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response['messages'][-1].content)"
      ],
      "metadata": {
        "id": "3Zww1Kyh4ijo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"How is the weather in Seoul? And who's the current President of Korea?\")]\n",
        "# messages = [HumanMessage(content=\"Who's the current President of Korea?\")]\n",
        "response = alfred.invoke({\"messages\": messages})"
      ],
      "metadata": {
        "id": "klZrxrdU4kRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response['messages'][-1].content)"
      ],
      "metadata": {
        "id": "OFc4nYyh433V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"How is the weather in Seoul?\")]\n",
        "response = alfred.invoke({\"messages\": messages})"
      ],
      "metadata": {
        "id": "wH32CLBw44W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸŽ© Alfred's Response:\")\n",
        "print(response['messages'][-1].content)"
      ],
      "metadata": {
        "id": "HzMG8PkC444Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}